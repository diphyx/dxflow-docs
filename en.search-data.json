{"/about/":{"data":{"1-our-journey#1. Our Journey":"dxflow began as an internal initiative at DiPhyX to streamline sprawling scripts, clusters, and ad-hoc logs that slow down scientific progress. Initially a weekend hack intended to create a “MLFlow for physics and chemistry,” it has evolved through numerous projects in bioinformatics, CFD, and materials science into a robust, production-grade engine available for everyone.","2-our-mission#2. Our Mission":"We are committed to accelerating scientific innovation by offering a unified, scalable, and intuitive cloud platform for end-to-end computational pipelines. Every feature in dxflow is designed to help researchers:\nSpeed up discovery. Ensure reproducibility. Simplify complex computational workflows. ","3-what-we-offer#3. What We Offer":" Feature Benefit Run Anywhere Choose local workstations, on-prem HPC, or any major cloud with a simple flag toggle. Track Everything Automatically capture parameters, code versions, resources, results, and lineage. Reproducibility Generate immutable run records and environment snapshots to eliminate “it worked on my machine” issues. Production-Ready Tools Seamlessly move a validated model from prototype to service using the same commands that trained it. Built-in Post-Processing Launch a Jupyter notebook or connect your favorite BI tool without exporting data. ","4-why-dxflow-is-different#4. Why dxflow is Different":" Scientific-First Design: Engineered to work with a wide range of scientific tools, including GROMACS, Ansys Fluent, SU2, or custom Fortran/C++ solvers. End-to-End Integration: Manage everything from raw data ingestion to scheduled production pipelines without the need for additional glue scripts. Cost \u0026 Carbon Efficiency: Real-time dashboards display cost per result and CO₂ estimates, empowering labs to optimize both budgets and environmental impact. ","5-who-we-serve#5. Who We Serve":" Life-Science Researchers: Scale up studies on binding affinities with robust computational support. CFD Engineers: Iterate on aerodynamic design processes more rapidly. Data-Science Teams: Build physics-informed ML pipelines with ease. Academic Groups \u0026 Startups: Access HPC power without the overhead of managing complex infrastructures. ","6-built-by-scientists-for-scientists#6. Built by Scientists for Scientists":"Our core team brings over 20 years of combined experience on national supercomputers and has published more than 50 peer-reviewed papers. We understand the challenges of failed overnight runs and design dxflow to minimize such setbacks.","7-join-the-journey#7. Join the Journey":"Ready to move beyond cluster chaos and focus on groundbreaking insights?\nSign up for early access or schedule a demo to experience dxflow in action.","about-dxflow#About dxflow":"About dxflow"},"title":"about"},"/api/":{"data":{"authentication-guide#Authentication Guide":"Request a Challenge Method: GET Endpoint: /api/auth/challenge/ Description: Initiate the authentication process. On success, you’ll receive a JSON response containing: identity: Your identifier. nounce: A unique challenge string. lifetime: Duration for the challenge’s validity. Example:\ncurl http://localhost/api/auth/challenge/ Verify the Challenge Method: POST Endpoint: /api/auth/verify/ Content-Type: application/json Description: Submit your response to the issued challenge. A successful verification returns: token: A JWT token to use as your authentication credential. permissions: An array of permissions (e.g., MASTER, SHELL, others). expires_at: A timestamp (int64) indicating when the token expires. Example:\ncurl -X POST -H \"Content-Type: application/json\" \\ -d '{\"challenge_response\": \"your_response_data\"}' \\ http://localhost/api/auth/verify/ Inspect the Authentication Token Method: GET Endpoint: /api/auth/inspect/ Description: Validate your authentication token. Include your token as a Bearer token in the Authorization header. A status code of 202 indicates a valid token. Example:\ncurl -H \"Authorization: Bearer \u003cyour_token\u003e\" http://localhost/api/auth/inspect/ ","dxflow-api-reference#dxflow API Reference":"dxflow API ReferenceThe API can be accessed at http://localhost:8080/api/v1, through IP, or dxflow.ai proxy from a remote device, when the dxflow engine is running. The API provides endpoints for managing workflows, files, shells, and other resources. You can use tools like curl or Postman to interact with the API.","engine-management#Engine Management":"Healthcheck Method: GET Endpoint: /api/engine/healthcheck/ Description: Check the engine’s health status. On success, you’ll receive a JSON response confirming that the engine is healthy. Example:\ncurl http://localhost/api/engine/healthcheck/ Ping Method: GET Endpoint: /api/engine/ping/ Parameters: Query parameter: count (optional; defines the number of ping requests) Description: Send ping requests to the engine. A successful response returns a JSON array with integer values representing the ping responses. Example:\ncurl http://localhost/api/engine/ping/?count=5 Restart Engine Method: PUT Endpoint: /api/engine/restart/ Description: Initiate the engine restart procedure. On success, you’ll receive a JSON response confirming that the engine restart has been initiated. Example:\ncurl -X PUT http://localhost/api/engine/restart/ Endpoint Overview Description: Initiate a restart of the dxflow engine. Method: PUT Endpoint: http://localhost/api/engine/restart/ Authentication: Inherits the current authentication credentials via Bearer token. API Request JSON Configuration { \"v\": 8, \"id\": \"cmd1rg0e72ll1vw1aog89a9wi\", \"name\": \"Engine Management\", \"folders\": [], \"requests\": [ { \"v\": \"14\", \"name\": \"restart\", \"method\": \"PUT\", \"endpoint\": \"http://localhost/api/engine/restart/\", \"params\": [], \"headers\": [], \"preRequestScript\": \"\", \"testScript\": \"\", \"auth\": { \"authType\": \"inherit\", \"authActive\": true }, \"body\": { \"contentType\": null, \"body\": null }, \"requestVariables\": [], \"responses\": { \"Engine restart initiated\": { \"name\": \"Engine restart initiated\", \"originalRequest\": { \"v\": \"5\", \"name\": \"restart\", \"method\": \"PUT\", \"endpoint\": \"http://localhost/api/engine/restart/\", \"headers\": [], \"params\": [], \"body\": { \"contentType\": null, \"body\": null }, \"auth\": { \"authType\": \"bearer\", \"token\": \"\", \"authActive\": true }, \"requestVariables\": [] }, \"status\": \"OK\", \"code\": 200, \"headers\": [ { \"key\": \"content-type\", \"value\": \"application/json\" } ], \"body\": \"{\\\"schema\\\":{\\\"type\\\":\\\"string\\\"}}\" } } } ], \"auth\": { \"authType\": \"inherit\", \"authActive\": true }, \"headers\": [], \"_ref_id\": \"coll_md24hb5m_728cc125-5dbb-4c25-aade-86832744a3e4\" } Usage Example To trigger the engine restart, you can issue the following command:\ncurl -X PUT http://localhost/api/engine/restart/ On success, the engine will initiate a restart, and you will receive a JSON response indicating that the restart has been initiated.","key-management#Key Management":"List Keys Method: GET Endpoint: /api/auth/key/ Parameters: Query parameter: all (optional) Description: Retrieve the list of authorized keys. On success, the response will include an array of key objects containing: identity: Identifier for the key. key: Key string. permissions: An array of permission strings. disabled: A boolean indicating if the key is disabled. created_at: ISO formatted timestamp. Example:\ncurl http://localhost/api/auth/key/?all= Register a Key Method: POST Endpoint: /api/auth/key/ Content-Type: application/json Description: Register a new key. Provide a JSON payload with: identity: Identifier to associate with the key. permissions: An array of permission strings. Example:\ncurl -X POST -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"your_identity\", \"permissions\": [\"PERMISSION1\", \"PERMISSION2\"]}' \\ http://localhost/api/auth/key/ Unregister a Key Method: DELETE Endpoint: /api/auth/key/ Content-Type: application/json Description: Unregister an existing key. Provide a JSON payload identifying the key to remove (e.g., via its identity). Example:\ncurl -X DELETE -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"your_identity\"}' \\ http://localhost/api/auth/ ","object-management-api-reference#Object Management API Reference":"This section documents endpoints for managing filesystem objects such as listing, creating, deleting, uploading, downloading, renaming, zipping, unzipping, sharing, and batch deletion.\nList Filesystem Objects Method: GET Endpoint: /api/object/fs/ Parameters: directory (query) all (query) pattern (query) depth (query) offset (query) limit (query) Description:\nRetrieve an array of filesystem objects. Each object typically includes properties like identity, name, permission, size, and modified_at (UNIX timestamp).\nExample:\ncurl \"http://localhost/api/object/fs/?directory=path/to/dir\u0026all=true\" Create Filesystem Object Method: POST Endpoint: /api/object/fs/ Content-Type: application/json Description:\nRegister or create a new filesystem object. Provide the necessary JSON payload structure.\nExample:\ncurl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"new_object\", \"permission\": \"read\"}' http://localhost/api/object/fs/ Delete Filesystem Object Method: DELETE Endpoint: /api/object/fs/ Content-Type: application/json Description:\nRemove an existing filesystem object by providing its identifier within a JSON payload.\nExample:\ncurl -X DELETE -H \"Content-Type: application/json\" -d '{\"identity\": \"object_id\"}' http://localhost/api/object/fs/ Upload Filesystem Object Method: PUT Endpoint: /api/object/fs/upload/ Content-Type: application/octet-stream Parameters: identity (query) force (query) Description:\nUpload a file stream to create or replace a filesystem object. Use query parameters to specify the target identity and whether to force the upload.\nExample:\ncurl -X PUT --data-binary \"@file.bin\" \"http://localhost/api/object/fs/upload/?identity=object_id\u0026force=true\" Upload Pre-signed Filesystem Object Method: PUT Endpoint: /api/object/fs/presigned/upload/ Content-Type: application/octet-stream Parameter: signature (query) Description:\nUpload a file using a pre-generated signature. No authentication is required.\nExample:\ncurl -X PUT --data-binary \"@file.bin\" \"http://localhost/api/object/fs/presigned/upload/?signature=your_signature\" Download Filesystem Object Method: GET Endpoint: /api/object/fs/download/ Parameter: identity (query) Description:\nDownload a file corresponding to a filesystem object. The response is delivered with a binary content type.\nExample:\ncurl \"http://localhost/api/object/fs/download/?identity=object_id\" --output downloaded_file.bin Download Pre-signed Filesystem Object Method: GET Endpoint: /api/object/fs/presigned/download/ Parameter: signature (query) Description:\nDownload a file using a pre-approved signature. No authentication is needed.\nExample:\ncurl \"http://localhost/api/object/fs/presigned/download/?signature=your_signature\" --output downloaded_file.bin Rename Filesystem Object Method: PUT Endpoint: /api/object/fs/rename/ Content-Type: application/json Description:\nRename a filesystem object by providing a payload that includes the current identity and a new_identity.\nExample:\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"identity\": \"old_name\", \"new_identity\": \"new_name\"}' http://localhost/api/object/fs/rename/ Zip Filesystem Object Method: PUT Endpoint: /api/object/fs/zip/ Content-Type: application/json Description:\nCompress one or more filesystem objects. The JSON payload should include necessary details, and the response provides a destination path.\nExample:\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"identity\": \"folder_id\", \"destination\": \"archive.zip\"}' http://localhost/api/object/fs/zip/ Unzip Filesystem Object Method: PUT Endpoint: /api/object/fs/unzip/ Content-Type: application/json Description:\nExtract a zipped filesystem object. The JSON payload should specify the source and optionally the destination path.\nExample:\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"identity\": \"archive.zip\", \"destination\": \"extracted_folder\"}' http://localhost/api/object/fs/unzip/ Share Filesystem Object Method: PUT Endpoint: /api/object/fs/share/ Content-Type: application/json Description:\nShare one or more filesystem objects. The payload usually details which objects to share. The response returns an array containing sharing signatures along with expiry details.\nExample:\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"identities\": [\"object_id1\", \"object_id2\"]}' http://localhost/api/object/fs/share/ Batch Delete Filesystem Objects Method: DELETE Endpoint: /api/object/fs/batch/ Content-Type: application/json Description:\nDelete multiple filesystem objects in a single request. The JSON payload should list the identifiers of objects to remove. The response indicates the deletion status for each.\nExample:\ncurl -X DELETE -H \"Content-Type: application/json\" -d '{\"identities\": [\"object_id1\", \"object_id2\"]}' http://localhost/api/object/fs/batch/ ","shell-management-api-reference#Shell Management API Reference":"This section explains the endpoints used for managing shell sessions. The endpoints allow you to list existing shells, create new ones, remove shells (individually or in batches), connect to shells via WebSocket, resize shell dimensions, execute commands, and kill shells. Use these API calls to efficiently manage shell resources within your system.\nList Shells Method: GET Endpoint: /api/shell/ Parameters:\n- offset (query; for pagination; specifies the start index)\n- limit (query; for pagination; specifies the number of items to return) Description:\nRetrieves a list of active shell sessions including details like the shell’s identity, command path, arguments, current state, terminal dimensions (columns and rows), session count, and creation timestamp. Example:\ncurl \"http://localhost/api/shell/?offset=0\u0026limit=10\" Create Shell Method: POST Endpoint: /api/shell/ Content-Type: application/json Description:\nCreates a new shell session. Provide a JSON payload with configuration settings (for example, the command to run and optional arguments). On success, the API returns details of the created shell. Example:\ncurl -X POST -H \"Content-Type: application/json\" \\ -d '{\"config\": {\"command\": \"/bin/bash\", \"args\": [\"-l\"]}}' \\ http://localhost/api/shell/ Remove Shell Method: DELETE Endpoint: /api/shell/ Content-Type: application/json Description:\nRemoves an active shell session. Specify the shell’s identifier in the JSON payload. Example:\ncurl -X DELETE -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"shell_id\"}' \\ http://localhost/api/shell/ Connect to Shell Method: GET Endpoint: /api/shell/\u003c\u003cidentity\u003e\u003e/ Description:\nEstablishes a WebSocket connection to the specified shell session. Replace \u003c\u003cidentity\u003e\u003e with the desired shell’s identifier. A successful request upgrades the protocol to WebSocket. Example:\ncurl -i -N -H \"Connection: Upgrade\" -H \"Upgrade: websocket\" \\ http://localhost/api/shell/shell_id/ Resize Shell Method: PUT Endpoint: /api/shell/resize/ Content-Type: application/json Description:\nAdjusts the dimensions of an active shell session. Include the shell identity along with new columns and rows values in the JSON payload. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"shell_id\", \"columns\": 120, \"rows\": 30}' \\ http://localhost/api/shell/resize/ Execute Shell Command Method: PUT Endpoint: /api/shell/execute/ Content-Type: application/json Description:\nExecutes a specific command within an active shell session. Provide the shell identifier and the command to run in the JSON payload. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"shell_id\", \"command\": \"ls -la\"}' \\ http://localhost/api/shell/execute/ Kill Shell Method: PUT Endpoint: /api/shell/kill/ Content-Type: application/json Description:\nTerminates a specific shell session. Provide the shell’s identifier within the JSON payload. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"shell_id\"}' \\ http://localhost/api/shell/kill/ Batch Remove Shells Method: DELETE Endpoint: /api/shell/batch/ Content-Type: application/json Description:\nDeletes multiple shell sessions in one request. Provide an array of shell identities in the JSON payload to remove them in batch. Example:\ncurl -X DELETE -H \"Content-Type: application/json\" \\ -d '{\"identities\": [\"shell_id1\", \"shell_id2\"]}' \\ http://localhost/api/shell/batch/ By using the endpoints above, you have complete control over shell session management, including monitoring, configuration changes, and cleanup operations.\nStop Compose Workflow Method: PUT Endpoint: /api/workflow/compose/stop/ Content-Type: application/json Description:\nStop a running compose workflow. Upon success, the API returns a status confirmation. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"workflow_id\"}' \\ http://localhost/api/workflow/compose/stop/ Pause Compose Workflow Method: PUT Endpoint: /api/workflow/compose/pause/ Content-Type: application/json Description:\nPause an active compose workflow without stopping it completely. A confirmation in JSON is returned on success. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"workflow_id\"}' \\ http://localhost/api/workflow/compose/pause/ Unpause Compose Workflow Method: PUT Endpoint: /api/workflow/compose/unpause/ Content-Type: application/json Description:\nResume a paused workflow. Confirm that the workflow is reinstated with a JSON response. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"workflow_id\"}' \\ http://localhost/api/workflow/compose/unpause/ Execute Compose Workflow Method: PUT Endpoint: /api/workflow/compose/execute/ Content-Type: application/json Description:\nExecute a command on the given compose workflow. Ideal for triggering actions or updating configurations dynamically. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"workflow_id\", \"command\": \"your_command\"}' \\ http://localhost/api/workflow/compose/execute/ Kill Compose Workflow Method: PUT Endpoint: /api/workflow/compose/kill/ Content-Type: application/json Description:\nForcefully terminate a compose workflow that is not responding to normal stop commands. Returns a confirmation message in JSON. Example:\ncurl -X PUT -H \"Content-Type: application/json\" \\ -d '{\"identity\": \"workflow_id\"}' \\ http://localhost/api/workflow/compose/kill/ "},"title":"_index"},"/cli/":{"data":{"command-line-interface-cli#Command Line Interface (CLI)":"Command Line Interface (CLI)dxflow command line interface (CLI) is a powerful tool that allows you to interact with the dxflow engine directly from your terminal. It provides a wide range of commands for managing workflows, files, and system operations.\ndxflow --help dxflow-engine command line interface Usage: dxflow [command] Aliases: dxflow, dxf Available Commands: auth Authentication control engine Engine management \u0026 monitoring workflow Workflow management object Object management shell Shell access config Config control help Help about any command Flags: -C, --config-profile string specify the config profile (default \"default\") -L, --log-level string specify the log level [debug, error, disabled] (default \"disabled\") -N, --no-color disable color output -h, --help help for dxflow -v, --version version for dxflow Use \"dxflow [command] --help\" for more information about a command. "},"title":"_index"},"/cli/engine/":{"data":{"dxflow-engine#\u003ccode\u003edxflow engine\u003c/code\u003e":"","dxflow-engine-boot#\u003ccode\u003edxflow engine Boot\u003c/code\u003e":"","dxflow-engine-healthcheck#\u003ccode\u003edxflow engine healthcheck\u003c/code\u003e":"","dxflow-engine-key#\u003ccode\u003edxflow engine key\u003c/code\u003e":"","dxflow-engine-management#dxflow Engine Management":"","dxflow-engine-ping#\u003ccode\u003edxflow engine ping\u003c/code\u003e":"","dxflow-engine-token#\u003ccode\u003edxflow engine token\u003c/code\u003e":"dxflow engineThe dxflow engine command provides comprehensive tools for managing the engine, including boot control, health checks, authorized key management, pinging the engine, and generating tokens. Below is a detailed breakdown of each subcommand and its options.\ndxflow Engine Management Synopsis Engine management commands for dxflow.\nOptions help (-h): Displays help information for the engine command. Default: false. Inherited Options config-profile (-C): Specifies the configuration profile to use. Default: default. log-level (-L): Sets the log level. Options: debug, error, disabled. Default: disabled. no-color (-N): Disables color output. Default: false. See Also dxflow engine boot: Engine boot control. dxflow engine healthcheck: Check the engine health. dxflow engine key: Authorized key control. dxflow engine ping: Send ping to the engine. dxflow engine token: Generate authorized token. dxflow engine Boot Synopsis Controls the boot state of the engine.\nOptions help (-h): Displays help information for the boot command. Default: false. dxflow engine healthcheck Synopsis Checks the health of the engine.\nUsage dxflow engine healthcheck [flags]\nOptions help (-h): Displays help information for the healthcheck command. Default: false. dxflow engine key Synopsis Manages authorized keys for the engine.\nOptions help (-h): Displays help information for the key command. Default: false. dxflow engine ping Synopsis Sends a ping to the engine.\nUsage dxflow engine ping [flags]\nOptions count (-c): Specifies the number of pings to send. Default: 3. help (-h): Displays help information for the ping command. Default: false. dxflow engine token Synopsis Generates an authorized token for the engine.\nUsage dxflow engine token [flags]\nOptions help (-h): Displays help information for the token command. Default: false. "},"title":"engine"},"/cli/file_system/":{"data":{"dxflow-file-system-management#dxflow File System Management":"","dxflow-fs#\u003ccode\u003edxflow fs\u003c/code\u003e":"","dxflow-fs-create#\u003ccode\u003edxflow fs create\u003c/code\u003e":"","dxflow-fs-delete#\u003ccode\u003edxflow fs delete\u003c/code\u003e":"","dxflow-fs-download#\u003ccode\u003edxflow fs download\u003c/code\u003e":"","dxflow-fs-list#\u003ccode\u003edxflow fs list\u003c/code\u003e":"","dxflow-fs-rename#\u003ccode\u003edxflow fs rename\u003c/code\u003e":"","dxflow-fs-share#\u003ccode\u003edxflow fs share\u003c/code\u003e":"","dxflow-fs-unzip#\u003ccode\u003edxflow fs unzip\u003c/code\u003e":"","dxflow-fs-upload#\u003ccode\u003edxflow fs upload\u003c/code\u003e":"","dxflow-fs-zip#\u003ccode\u003edxflow fs zip\u003c/code\u003e":"dxflow fsThe dxflow fs command provides a suite of subcommands to manage filesystem objects. You can create, delete, download, list, rename, share, unzip, upload, and zip filesystem objects.\ndxflow File System Management Synopsis Filesystem management commands for dxflow fs.\nUsage dxflow fs [flags]\nInherited Options config-profile (-C): Specifies the config profile. Default: default. log-level (-L): Sets the log level. Options: debug, error, disabled. Default: disabled. no-color (-N): Disables color output. Default: false. dxflow fs create Synopsis Create a filesystem object.\nUsage dxflow fs create [flags]\nOptions directory (-d): Make a directory. Default: false. force (-f): Force creation if the object already exists. Default: false. help (-h): Displays help information for the create command. Default: false. dxflow fs delete Synopsis Delete a filesystem object.\nUsage dxflow fs delete [flags]\nOptions help (-h): Displays help information for the delete command. Default: false. dxflow fs download Synopsis Download a filesystem object.\nUsage dxflow fs download [DESTINATION] [flags]\nOptions force (-f): Force creation if the object already exists. Default: false. help (-h): Displays help information for the download command. Default: false. dxflow fs list Synopsis List filesystem objects.\nUsage dxflow fs list [DIRECTORY] [flags]\nOptions all (-a): Include hidden objects. Default: false. depth (-d): Depth of subdirectories to include. Default: 0. pattern (-p): Pattern to filter objects. help (-h): Displays help information for the list command. Default: false. dxflow fs rename Synopsis Rename a filesystem object.\nUsage dxflow fs rename \u003cNEW_IDENTITY\u003e [flags]\nOptions help (-h): Displays help information for the rename command. Default: false. dxflow fs share Synopsis Share a filesystem object.\nUsage dxflow fs share [flags]\nOptions lifetime (-l): Lifetime of the share. Default: 5m. writable (-w): Mark as writable object. Default: false. help (-h): Displays help information for the share command. Default: false. dxflow fs unzip Synopsis Unzip a filesystem object.\nUsage dxflow fs unzip [flags]\nOptions quiet (-q): Suppress progress output. Default: false. help (-h): Displays help information for the unzip command. Default: false. dxflow fs upload Synopsis Upload a filesystem object.\nUsage dxflow fs upload [IDENTITY] [flags]\nOptions force (-f): Force creation if the object already exists. Default: false. help (-h): Displays help information for the upload command. Default: false. dxflow fs zip Synopsis Zip a filesystem object.\nUsage dxflow fs zip [flags]\nOptions quiet (-q): Suppress progress output. Default: false. help (-h): Displays help information for the zip command. Default: false. "},"title":"file_system"},"/cli/key/":{"data":{"dxflow-key#dxflow key":"","dxflow-key-list#\u003ccode\u003edxflow key list\u003c/code\u003e":"","dxflow-key-management#dxflow Key Management":"","dxflow-key-register#\u003ccode\u003edxflow key register\u003c/code\u003e":"","dxflow-key-unregister#\u003ccode\u003edxflow key unregister\u003c/code\u003e":"dxflow keyThe dxflow key command provides a suite of subcommands to manage authentication keys. A key is a 2048-bit RSA key-pair used for authenticating with the dxflow engine. Each key is bound to an identity (similar to a username) and can be assigned one or more permissions (read, write, execute, admin).\ndxflow Key Management Synopsis Authentication key management commands for dxflow key.\nUsage dxflow key [flags]\nInherited Options config-profile (-C): Specifies the config profile. Default: default. log-level (-L): Sets the log level. Options: debug, error, disabled. Default: disabled. no-color (-N): Disables color output. Default: false. dxflow key list Synopsis List authorized keys.\nUsage dxflow key list [flags]\nOptions all (-a): Include disabled keys. Default: false. help (-h): Displays help information for the list command. Default: false. dxflow key register Synopsis Register an authorized key.\nUsage dxflow key register [flags]\nKey Details \u003cKEY\u003e: A 2048-bit RSA key-pair used for authentication. key identity (-i): Arbitrary value that uniquely identifies the key (similar to a username). permissions (-p): Assign one or more permissions. Valid values: read, write, execute, admin. Default: []. Options help (-h): Displays help information for the register command. Default: false. dxflow key unregister Synopsis Unregister an authorized key.\nUsage dxflow key unregister [flags]\nOptions help (-h): Displays help information for the unregister command. Default: false. "},"title":"key"},"/cli/profiles/":{"data":{"":"The purpose of profiles is to create a set for environmental variables that can be used to configure the dxflow engine. This allows you to easily switch between different configurations without having to manually set the environmental variables each time. It is especially useful when you want to connect to different dxflow engines or when you want to use different configurations for different workflows.\nIF you don’t want to use profile you can set the environmental variables directly in your shell or in your workflow file. The profiles are just a convenient way to manage the environmental variables. The\n🔧 All the config variables can be set in the Environment by using Environment case method (all capital with _ instead of -). define profile:\ndxflow.exe -C \u003cPROFILE_NAME\u003e config \u003cvariable\u003e \u003cvalue\u003e Profiles information are stored at ~/.dxflow/PROFILE_NAME_config.yaml, if you want to remove the profile from your dxflow, you can just delete the file manually.\nThere are several variables that can be set in the profile, such as:\nhttp-port: The port on which the dxflow engine will listen for HTTP requests. Default is 80. connection-address: The (IP) address of the dxflow engine. Default is 0.0.0.0. volume: The volume where the dxflow engine will store its data. Default is ~/.dxflow for Linux and MacOS, and C:\\ProgramData\\dxflow for Windows. secret: dxflow generate a secret key everytime use run it. To use a constant secret key, you can define it in the config file or environment variable. ⚠️ This method is not recommended for production use, as it is not secure.We suggest to use use the default method as its secrets have expiration time. dxflow.exe config secret \u003csecret\u003e In order to remove a config use unset command:\ndxflow.exe -C \u003cPROFILE_NAME\u003e config unset \u003cvariable\u003e 🔧 If you don’t use the -C flag, the default profile will be used. The default profile is created automatically when you run the dxflow command for the first time. You can also create a new profile by using the -C flag with any name you want. "},"title":"profiles"},"/getting-started/":{"data":{"":"","#":"What is dxflow? dxflow is an comprehensive interface, providing a unified way to manage and orchestrate your data \u0026 compute workflows across different computing environments. It has different features:\nAlso, it can be seen as a distributed-computing engine, helps to simplify utilizing computational resources and create a hybrid environment for your data \u0026 computational pipeline workflows.\nIn short: dxflow turns any machine you can boot into a first‑class citizen of your computational fleet, with one installer, a stable URL, and a unified interface for jobs, logs, and data. dxflow engine can be divided into two main parts:\nServer:\nIt is when you want to create a compute-unit to run your data \u0026 compute workflow. The server can be a closed system, such as a Slurm cluster, or a cloud-based system, such as AWS, GCP, or Azure. It can also be a local machine or a Docker container. Also, it can be accessible remotely or have no access at all. (see more detail on the Server section below)\nClient:\nIt is the interface that lets you access the server and run your data \u0026 compute workflows. It can be a command line interface (CLI), a web-based user interface (UI), or an API interface. The client can be used to create, start, stop, and monitor workflows, as well as manage files and other resources on the server.\nInfrastructure (Layer 1) – Raw compute: cloud VMs, GPU nodes, on‑prem clusters, or even your laptop.\ndxflow Engine (Layer 2) – A lightweight daemon you install on every compute‑unit. It auto‑registers with the control plane, stages data, authenticates users, and translates high‑level workflows into commands understood by the local scheduler/runtime.\nOrchestration Runtimes (Layer 3) – The native workload managers already living on the node (Kubernetes, Slurm, Docker, Singularity, MPI, etc.). dxflow talks to these via pluggable adapters so your YAML never changes when you switch environments.\nApplication Layer (Layer 4) – The domain software scientists actually run: simulation codes, bioinformatics pipelines, ML training loops, post‑processing scripts.\nWhy dxflow? Challenge How dxflow solves it Fragmented environments – every site has its own scheduler, security rules, and data paths. One runtime, one interface. Install dxflow everywhere and interact through a consistent CLI, REST/GRPC API, or web UI. Manual data staging slows researchers. Integrated file‑hub. Resumable uploads/downloads, cross‑node transfers, and automatic clean‑up built in. Bursty demand makes static clusters costly. Cloud‑agnostic bursting. Spin up spot instances or GPU farms on any provider, tear them down automatically when the queue drains. Security complexity across VPNs and firewalls. Auto‑provisioned TLS endpoints (.dxflow.ai) or Unix‑socket mode, plus RSA key‑pair auth with fine‑grained roles. Opaque job status on multi‑tool stacks. Real‑time dashboards \u0026 streaming logs flow back to the DiPhyx control plane—or your own dashboard—regardless of the underlying scheduler. Who needs dxflow? Techncly anyone who wants to manage and orchestrate their data \u0026 compute workflows can use dxflow. However, it is mainly designed for people who want to build and manage data pipelines and workflows across different computing environments. It can have many applications, such as:\nData Science Bioinformatics Computational Biology Distributed Computing Edge-Computing Or really any domain that requires a compute-unit to run data \u0026 compute workflows.\nSecurity \u0026 Privacy: dxflow use RSA security to authenticate users and services with the dxflow engine. RSA security using cryptography is a one of suggested practices to keep your data safe. dxflow provides different permission access levels, such as * read-only\nterminal file-management full access This allows you to control who can access your workflows and files, and what they can do with them. Also, the connection between dxflow servers are managed through SSL certificates, which provides a secure connection between the servers. This allows you to connect to remote dxflow servers securely and manage your workflows and files across different computing environments."},"title":"_index"},"/getting-started/installation/":{"data":{"#":"Download \u0026 Installationdxflow is a cross-platform tool, which means it can run on any operating system, such as Linux, macOS, and Windows. It is designed to be easy to install and use, with a simple command-line interface (CLI) and a web-based user interface (UI).\nDownload The fist step is to install the dxflow engine. You can do this by downloading the latest release from the GitHub releases page.\nHere are the links to the latest releases for each platform:\nx86 Linux x86 macOS x86 Windows x86 ARM64 Linux ARM64 macOS ARM64 Windows ARM64 Installation Steps LinuxMacOSWindows Step 1 Unizip the downloaded file to /usr/local/bin or any directory in your PATH. For example, on Linux, you can use the following command:\ntar -xvf dxflow_1.0.0_linux_amd64.tar.gz -C /usr/local/bin Step 2 Grant execute permissions with\nchmod +x /usr/local/bin/dxflow Step 1 Unzip the downloaded file to /usr/local/bin or any directory in your PATH. For example, on macOS, you can use the following command:\ntar -xvf dxflow_1.0.0_darwin_amd64.tar.gz -C /usr/local/bin Step 2 Grant execute permissions with\nchmod +x /usr/local/bin/dxflow Step 3 Verify installation\nOpen a new terminal and run dxflow --version Open System Settings, then Privacy \u0026 Security In the Security section, click the Open Anyway Click Open to allow the application to run Step 1 Unzip the downloaded file to C:\\Program Files\\diphyx directory\nStep 2 Open environment variables:\nPress Win + X, select System, then Advanced system settings. Click Environment Variables. Edit PATH. Select Path in System variables, click Edit. Click New, add C:\\Program Files\\diphyx, and click OK. Easy Installation - Only for Linux and macOS Copy and paste the following command in your terminal to install dxflow engine automatically. This script will download the latest release and install it for you.\nwget -qO- https://raw.githubusercontent.com/diphyx/dxflow-docs/main/getting-started/installation/install.sh | sudo bash -s dxflow ","download--installation#Download \u0026amp; Installation":""},"title":"installation"},"/getting-started/quick_start/":{"data":{"quick-start#Quick Start":"Quick StartThis guide will help you quickly set up and run a simple dxfloww project.\nThe first step is to install the dxflow engine. You can do this by downloading and installing the latest release by following the installation guide.\nNow that you have the dxflow engine installed, you can start using it. Lets check if the installation was successful by running the following command:\ndxflow --version This should display the version of the dxflow engine you have installed.\nNow lets start the dxflow engine with the following command:\ndxflowdxflow engine boot up --http -L debug This command will start the dxflow engine and open the HTTP port for access. The -L debug flag sets the log level to debug, which is useful for troubleshooting.\nThe --http flag enables the HTTP server, allowing you to interact with the dxflow engine via a web browser or HTTP client. The default port is 8080, so you can access the web interface at http://localhost:8080 in your browser.\nNow open the web interface in your browser by navigating to http://localhost:8080. You should see the dxflow engine dashboard, which allows you to manage workflows, files, and other resources.\nFor remote access"},"title":"quick_start"}}